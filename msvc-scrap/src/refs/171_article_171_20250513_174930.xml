<record>
  <isbns></isbns>
  <shortDBName>edsarx</shortDBName>
  <isiType>GEN</isiType>
  <notes></notes>
  <mid></mid>
  <language></language>
  <source></source>
  <bookEdition></bookEdition>
  <title>A probabilistic view on Riemannian machine learning models for SPD matrices</title>
  <pageEnd></pageEnd>
  <pageStart></pageStart>
  <peerReviewed></peerReviewed>
  <isOpenAccess></isOpenAccess>
  <publicationDate>20250505</publicationDate>
  <pageCount></pageCount>
  <publisherLocations></publisherLocations>
  <issue></issue>
  <identifiers></identifiers>
  <subjects>Computer Science - Machine Learning ; Mathematics - Statistics Theory ; Statistics - Machine Learning</subjects>
  <abstract>The goal of this paper is to show how different machine learning tools on the Riemannian manifold $\mathcal{P}_d$ of Symmetric Positive Definite (SPD) matrices can be united under a probabilistic framework. For this, we will need several Gaussian distributions defined on $\mathcal{P}_d$. We will show how popular classifiers on $\mathcal{P}_d$ can be reinterpreted as Bayes Classifiers using these Gaussian distributions. These distributions will also be used for outlier detection and dimension reduction. By showing that those distributions are pervasive in the tools used on $\mathcal{P}_d$, we allow for other machine learning tools to be extended to $\mathcal{P}_d$.</abstract>
  <pubTypes>Working Paper</pubTypes>
  <an>edsarx.2505.02402</an>
  <docTypes>Working Paper</docTypes>
  <volume></volume>
  <issns></issns>
  <degreeLevel></degreeLevel>
  <plink>https://research.ebsco.com/linkprocessor/plink?id=da82ac79-e194-3ca6-be3f-f140fa6affd6</plink>
  <doids></doids>
  <publisher></publisher>
  <contributors>de Surrel, Thibault ; Yger, Florian ; Lotte, Fabien ; Chevallier, Sylvain</contributors>
  <coverDate>20250505</coverDate>
  <longDBName>arXiv</longDBName>
  <doi></doi>
</record>
