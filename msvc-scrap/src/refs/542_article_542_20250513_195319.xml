<record>
  <isbns></isbns>
  <shortDBName>edsarx</shortDBName>
  <isiType>GEN</isiType>
  <notes></notes>
  <mid></mid>
  <language></language>
  <source></source>
  <bookEdition></bookEdition>
  <title>Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models</title>
  <pageEnd></pageEnd>
  <pageStart></pageStart>
  <peerReviewed></peerReviewed>
  <isOpenAccess></isOpenAccess>
  <publicationDate>20250428</publicationDate>
  <pageCount></pageCount>
  <publisherLocations></publisherLocations>
  <issue></issue>
  <identifiers></identifiers>
  <subjects>Computer Science - Machine Learning ; Computer Science - Artificial Intelligence</subjects>
  <abstract>Large language models (LLMs) have dramatically advanced machine learning research including natural language processing, computer vision, data mining, etc., yet they still exhibit critical limitations in reasoning, factual consistency, and interpretability. In this paper, we introduce a novel learning paradigm -- Modular Machine Learning (MML) -- as an essential approach toward new-generation LLMs. MML decomposes the complex structure of LLMs into three interdependent components: modular representation, modular model, and modular reasoning, aiming to enhance LLMs' capability of counterfactual reasoning, mitigating hallucinations, as well as promoting fairness, safety, and transparency. Specifically, the proposed MML paradigm can: i) clarify the internal working mechanism of LLMs through the disentanglement of semantic components; ii) allow for flexible and task-adaptive model design; iii) enable interpretable and logic-driven decision-making process. We present a feasible implementation of MML-based LLMs via leveraging advanced techniques such as disentangled representation learning, neural architecture search and neuro-symbolic learning. We critically identify key challenges, such as the integration of continuous neural and discrete symbolic processes, joint optimization, and computational scalability, present promising future research directions that deserve further exploration. Ultimately, the integration of the MML paradigm with LLMs has the potential to bridge the gap between statistical (deep) learning and formal (logical) reasoning, thereby paving the way for robust, adaptable, and trustworthy AI systems across a wide range of real-world applications.</abstract>
  <pubTypes>Working Paper</pubTypes>
  <an>edsarx.2504.20020</an>
  <docTypes>Working Paper</docTypes>
  <volume></volume>
  <issns></issns>
  <degreeLevel></degreeLevel>
  <plink>https://research.ebsco.com/linkprocessor/plink?id=968f5ef2-f59a-3f5c-b27f-2b5eee6ba33b</plink>
  <doids></doids>
  <publisher></publisher>
  <contributors>Wang, Xin ; Li, Haoyang ; Zhang, Zeyang ; Chen, Haibo ; Zhu, Wenwu</contributors>
  <coverDate>20250428</coverDate>
  <longDBName>arXiv</longDBName>
  <doi></doi>
</record>
