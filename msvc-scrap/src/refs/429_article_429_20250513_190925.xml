<record>
  <isbns></isbns>
  <shortDBName>eric</shortDBName>
  <isiType>JOUR</isiType>
  <notes></notes>
  <mid></mid>
  <language>eng</language>
  <source>Education and Information Technologies</source>
  <bookEdition></bookEdition>
  <title>Machine Learning Model for ChatGPT Usage Detection in Students' Answers to Open-Ended Questions: Case of Lithuanian Language</title>
  <pageEnd>18425</pageEnd>
  <pageStart>18403</pageStart>
  <peerReviewed>true</peerReviewed>
  <isOpenAccess></isOpenAccess>
  <publicationDate>20241001</publicationDate>
  <pageCount>23</pageCount>
  <publisherLocations></publisherLocations>
  <issue>14</issue>
  <identifiers></identifiers>
  <subjects>Artificial Intelligence ; Questioning Techniques ; Computer Software ; Synchronous Communication ; Technology Uses in Education ; Indo European Languages ; Algorithms</subjects>
  <abstract>The public availability of large language models, such as chatGPT, brings additional possibilities and challenges to education. Education institutions have to identify when large language models are used and when text is generated by the student itself. In this paper, chatGPT usage in students' answers is investigated. The main aim of the research was to build a machine learning model that could be used in the evaluation of students' answers to open-ended questions written in the Lithuanian language. The model should determine whether the answers were originally written students or answered with the help of chatGPT. A new dataset of student answers has been collected in to train machine learning models. The dataset consists of original student answers, chatGPT answers, and paraphrased chatGPT answers. A total of more than 1000 answers have been prepared. 24 combinations of text pre-processing algorithms have been analyzed. In text pre-processing, the main focus was on various tokenization methods, such as the Bag of Words and Ngrams, the stemming algorithm, and the stop words list. For the analyzed dataset, these pre-processing methods were more effective than application of multilanguage BERT for document embedding. Based on the features/properties of the dataset, the following learning algorithms have been investigated: artificial neural networks, decision trees, random forest, gradient boosting trees, k-nearest neighbours, and naive Bayes. The main results show that the highest accuracy of 87% in some cases can be obtained using gradient boosting trees, random forests, and artificial neural network algorithms. The lowest accuracy has been obtained using the k-nearest neighbouring algorithm. Furthermore, the results of experimental research suggest that the usage of chatGPT in student answers can be automatically identified.</abstract>
  <pubTypes>Academic Journal</pubTypes>
  <an>EJ1445928</an>
  <docTypes>Journal Articles ; Reports - Research</docTypes>
  <volume>29</volume>
  <issns>1360-2357 ; 1573-7608</issns>
  <degreeLevel></degreeLevel>
  <plink>https://research.ebsco.com/linkprocessor/plink?id=02fe4786-a54f-3da1-8354-452413efc8d1</plink>
  <doids></doids>
  <publisher></publisher>
  <contributors>Pavel Stefanovic ; Birute Pliuskuviene ; Urte Radvilaite ; Simona Ramanauskaite</contributors>
  <coverDate>2024</coverDate>
  <longDBName>ERIC</longDBName>
  <doi>10.1007/s10639-024-12589-z</doi>
</record>
